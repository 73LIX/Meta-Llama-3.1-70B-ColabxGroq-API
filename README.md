# Meta-Llama-3.1-70B-ColabxGroq-API

Meta Llama 3.1-70B is one of the open source LLM released by meta It is a very capable model with a whopping 70 billion parameters. It supports 8 Languages `English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai`.

Here we are using Groq API to get access to the model and run it. Since all the inference is done through Groq API, you can run this notebook on the basic `CPU Runtime` without any gpu. And honestly its really fast.

NOTE: The first stepðŸ¥‡ is to get your own [Groq-API](https://console.groq.com/keys) from their website. Just click on the link then sign up and create your own API.

The next step is to copy and save your API key in the `colab secretes tab`.<br> Just paste the API Key into the value section and name it `GROQ_API_KEY`.

| |Google Colab|
|:--|:-:|
| ðŸŒŸ **Llama 3.1-70B-ColabxGroq** |  [![Open in Colab](https://github.com/73LIX/Meta-Llama-3.1-8BxColab/blob/main/asset/colab_logo.svg)](https://colab.research.google.com/drive/1_B3vedI7H994TIm8w0f82Meguj-TtJt0?usp=sharing)
